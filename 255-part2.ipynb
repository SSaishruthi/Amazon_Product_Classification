{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ss/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from six.moves import html_parser\n",
    "#from html.parser import HTMLParser\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df1 = getDF('baby.json.gz')\n",
    "df2 = getDF('mus_inst.json.gz')\n",
    "df3 = getDF('beauty.json.gz')\n",
    "df4 = getDF('cloth_shoes.json.gz')\n",
    "df5 = getDF('health_PC.json.gz')\n",
    "df6 = getDF('home_kitchen.json.gz')\n",
    "df7 = getDF('off_prod.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_split = df1[0:1000]\n",
    "df2_split = df2[0:1000]\n",
    "df3_split = df3[0:1000]\n",
    "df4_split = df4[0:1000]\n",
    "df5_split = df5[0:1000]\n",
    "df6_split = df6[0:1000]\n",
    "df7_split = df7[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [df1_split, df2_split, df3_split, df4_split, df5_split, df6_split, df7_split]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['categories','title']\n",
    "df_final = pd.DataFrame(df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  concatenate_path(category):\n",
    "     try:\n",
    "        return ( ' -> '.join((category)[0]))\n",
    "     except IndexError:\n",
    "        return 'no-category'\n",
    "     except TypeError:\n",
    "        return 'no-category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final['categories_path'] =  df_final['categories'].apply(concatenate_path)\n",
    "df_final.dropna(subset=['title'], inplace=True)\n",
    "df_final = df_final[df_final['categories_path'] != 'no-category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_path_df = df_final.groupby('categories_path').agg({'title': 'count'}).sort_values(by='title', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_path_df.sort_values(by='categories_path', inplace=True)\n",
    "category_path_df['category_path_next'] = category_path_df['categories_path'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_path_list = []\n",
    "for i, value in category_path_df.iterrows():\n",
    "    category_path = value['categories_path']\n",
    "    category_path_next = value['category_path_next']\n",
    "    if str(category_path) not in str(category_path_next):\n",
    "        category_path_list.append(category_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_path_df = pd.DataFrame(category_path_list, columns=['category_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['categories_path'].isin(category_path_df['category_path'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_title(cat_title):\n",
    "    try:\n",
    "        en_title = unicodedata.normalize('NFKD', unicode(cat_title, 'utf-8', 'ignore')).encode('ascii', 'ignore')\n",
    "        en_title = BeautifulSoup(en_title, \"lxml\").encode('ascii', 'ignore')\n",
    "        en_title = en_title.lower()\n",
    "        excluded='-/.%'\n",
    "        en_title=re.split(\"[^\" + excluded + \"\\w]+\",en_title)\n",
    "        word_set= [token for token in  en_title if not token.isdigit()]\n",
    "        stop = set(stopwords.words('english'))\n",
    "        word_set = [w for w in word_set if not w in stop]\n",
    "        word_set = [w for w in word_set if len(w) > 2]\n",
    "        en_title=(\" \".join(word_set))\n",
    "        \n",
    "    except TypeError:  \n",
    "        en = 'NA'\n",
    "\n",
    "    return en_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final['title'] =  df_final['title'].apply(enc_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4567, 27349)\n"
     ]
    }
   ],
   "source": [
    "#tr1_x, ts1_x, tr1_y, ts1_y = train_test_split(df_final.title, df_final.categories_path, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm = 'l2',min_df = 0, use_idf = True, smooth_idf = False, sublinear_tf = True,ngram_range=(1,2))\n",
    "train_vect = vectorizer.fit_transform(df_final.title)\n",
    "train_vect = train_vect.toarray()\n",
    "print train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"train_vectorizer.pkl\", \"wb\"))\n",
    "pickle.dump(train_vect, open(\"train_matrix.pkl\", \"wb\"))\n",
    "pickle.dump(df_final.categories_path, open(\"train_result.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"train_vectorizer.pkl\", \"rb\"))\n",
    "vect =  pickle.load(open(\"train_matrix.pkl\", \"rb\"))\n",
    "lab =  pickle.load(open(\"train_result.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FindNeighbor(inp_csr, K):\n",
    "    output = []\n",
    "    for row in inp_csr:\n",
    "        #get single row from input scr matrix\n",
    "        row = np.array(row)\n",
    "        #sort and get 'k' nearest neighbor indexes\n",
    "        max_row = np.argpartition(-row, K)\n",
    "        top_rows = max_row[:K]\n",
    "        print max_row\n",
    "        result = []\n",
    "        for i in range(len(top_rows)):\n",
    "            \n",
    "            val = top_rows[i]\n",
    "            result.append(lab[val])\n",
    "            \n",
    "        output.append(result)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-895e6bc897ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsr_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFindNeighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr_sim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test_vect = model.transform(ts_y)\n",
    "test_vect = test_vect.toarray()\n",
    "csr_sim = cosine_similarity(test_vect, vect)\n",
    "output = FindNeighbor(csr_sim,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Home & Kitchen -> Kitchen & Dining -> Kitchen Knives & Cutlery Accessories -> Carving Knives & Forks -> Carving Knives'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab[3515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
